{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts learned in this section, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with polynomial features/interactions\n",
    "- Perform regularization\n",
    "- Use AIC and BIC to select the best value for the regularization parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a Baseline Boston Housing Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Boston housing data set, use all the predictors in their scaled version (using `preprocessing.scale`. Look at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation this time and use the $R^2$ score to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176778617934925"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = pd.DataFrame(boston.target, columns=[\"target\"])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "scaled_X = pd.DataFrame(scaled_X, columns=X.columns)\n",
    "scaled_X.head()\n",
    "\n",
    "LR = LinearRegression()\n",
    "\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "baseline = np.mean(cross_val_score(LR, scaled_X, y, scoring=\"r2\", cv=crossvalidation))\n",
    "\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold classification and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "You've created code for this before in the interactions lab, yet this time, you have scaled the variables so the outcomes may look different. \n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from itertools import combinations\n",
    "combinations = list(combinations(boston.feature_names, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 7 interactions: [('RM', 'LSTAT', 0.783), ('RM', 'TAX', 0.775), ('RM', 'RAD', 0.77), ('RM', 'PTRATIO', 0.764), ('INDUS', 'RM', 0.757), ('NOX', 'RM', 0.746), ('RM', 'AGE', 0.742)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "interactions = []\n",
    "data = scaled_X.copy()\n",
    "\n",
    "for comb in combinations:\n",
    "    data[\"interaction\"] = data[comb[0]] * data[comb[1]]\n",
    "    score = np.mean(cross_val_score(LR, data, y, scoring=\"r2\", cv=crossvalidation))\n",
    "    if score > baseline: interactions.append((comb[0], comb[1], round(score,3)))\n",
    "            \n",
    "print(\"Top 7 interactions: %s\" %sorted(interactions, key=lambda inter: inter[2], reverse=True)[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = sorted(interactions, key=lambda inter: inter[2], reverse=True)[:7]\n",
    "df_inter = scaled_X.copy()\n",
    "\n",
    "for i in inter:\n",
    "    df_inter[i[0]+'_'+i[1]] = df_inter[i[0]] * df_inter[i[1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM_LSTAT</th>\n",
       "      <th>RM_TAX</th>\n",
       "      <th>RM_RAD</th>\n",
       "      <th>RM_PTRATIO</th>\n",
       "      <th>INDUS_RM</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>-0.444930</td>\n",
       "      <td>-0.275757</td>\n",
       "      <td>-0.406574</td>\n",
       "      <td>-0.603547</td>\n",
       "      <td>-0.532772</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>-0.095668</td>\n",
       "      <td>-0.191813</td>\n",
       "      <td>-0.168607</td>\n",
       "      <td>-0.058883</td>\n",
       "      <td>-0.115279</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>-1.550451</td>\n",
       "      <td>-1.266461</td>\n",
       "      <td>-1.113245</td>\n",
       "      <td>-0.388783</td>\n",
       "      <td>-0.761138</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>-1.383713</td>\n",
       "      <td>-1.124148</td>\n",
       "      <td>-0.765197</td>\n",
       "      <td>0.114875</td>\n",
       "      <td>-1.328183</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>-1.261136</td>\n",
       "      <td>-1.358947</td>\n",
       "      <td>-0.925023</td>\n",
       "      <td>0.138869</td>\n",
       "      <td>-1.605599</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  RM_LSTAT  \\\n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562 -0.444930   \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439 -0.095668   \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727 -1.550451   \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517 -1.383713   \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501 -1.261136   \n",
       "\n",
       "     RM_TAX    RM_RAD  RM_PTRATIO  INDUS_RM    NOX_RM    RM_AGE  \n",
       "0 -0.275757 -0.406574   -0.603547 -0.532772 -0.059659 -0.049646  \n",
       "1 -0.191813 -0.168607   -0.058883 -0.115279 -0.143814  0.071331  \n",
       "2 -1.266461 -1.113245   -0.388783 -0.761138 -0.949544 -0.340960  \n",
       "3 -1.124148 -0.765197    0.114875 -1.328183 -0.848901 -0.823092  \n",
       "4 -1.358947 -0.925023    0.138869 -1.605599 -1.026210 -0.628023  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include Polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of 2, 3 and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 polynomials: [('RM', 4, 0.8), ('RM', 2, 0.782), ('LSTAT', 4, 0.782), ('RM', 3, 0.781), ('LSTAT', 3, 0.774), ('LSTAT', 2, 0.772), ('DIS', 3, 0.737), ('DIS', 2, 0.732), ('DIS', 4, 0.731), ('TAX', 4, 0.724)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomials = []\n",
    "\n",
    "# iterating through the df columns\n",
    "for col in scaled_X.columns:\n",
    "    # for each columns iterating through a list of numbers of polynomials to use\n",
    "    for degree in [2,3,4]:\n",
    "        \n",
    "        data = scaled_X.copy()\n",
    "        \n",
    "        poly = PolynomialFeatures(degree, include_bias=False)\n",
    "        X = poly.fit_transform(scaled_X[[col]])\n",
    "        \n",
    "        data = pd.concat([data.drop(col, axis=1),pd.DataFrame(X)], axis = 1)\n",
    "        \n",
    "        score = np.mean(cross_val_score(LR, data, y, scoring=\"r2\", cv=crossvalidation))\n",
    "        if score > baseline: polynomials.append((col, degree, round(score,3)))\n",
    "            \n",
    "print(\"Top 10 polynomials: %s\" %sorted(polynomials, key=lambda poly: poly[2], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "ZN         0.723\n",
       "INDUS      0.723\n",
       "CHAS       0.718\n",
       "NOX        0.721\n",
       "RM         0.800\n",
       "AGE        0.722\n",
       "DIS        0.737\n",
       "RAD        0.720\n",
       "TAX        0.724\n",
       "PTRATIO    0.721\n",
       "B          0.720\n",
       "LSTAT      0.782\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "polynom = pd.DataFrame(polynomials)\n",
    "polynom.groupby([0], sort=False)[2].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding Polynomial terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two feature, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "for col in [\"RM\", \"LSTAT\"]:\n",
    "    poly = PolynomialFeatures(4, include_bias=False)\n",
    "    X = poly.fit_transform(scaled_X[[col]])\n",
    "    colnames= [col, col+\"_\"+\"2\", col+\"_\"+\"3\", col+\"_\"+\"4\"]\n",
    "    df_inter = pd.concat([df_inter.drop(col, axis=1),pd.DataFrame(X, columns=colnames)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "      <th>RM</th>\n",
       "      <th>RM_2</th>\n",
       "      <th>RM_3</th>\n",
       "      <th>RM_4</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>LSTAT_2</th>\n",
       "      <th>LSTAT_3</th>\n",
       "      <th>LSTAT_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>0.171124</td>\n",
       "      <td>0.070789</td>\n",
       "      <td>0.029284</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>1.156834</td>\n",
       "      <td>-1.244247</td>\n",
       "      <td>1.338266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.037743</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>0.242497</td>\n",
       "      <td>-0.119415</td>\n",
       "      <td>0.058805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>1.645354</td>\n",
       "      <td>2.110519</td>\n",
       "      <td>2.707191</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>1.461022</td>\n",
       "      <td>-1.765977</td>\n",
       "      <td>2.134585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>1.032871</td>\n",
       "      <td>1.049709</td>\n",
       "      <td>1.066822</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>1.853728</td>\n",
       "      <td>-2.523882</td>\n",
       "      <td>3.436308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>1.509401</td>\n",
       "      <td>1.854414</td>\n",
       "      <td>2.278290</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>1.053705</td>\n",
       "      <td>-1.081630</td>\n",
       "      <td>1.110295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX       AGE       DIS  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217 -0.120013  0.140214   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.367166  0.557160   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262 -0.265812  0.557160   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284 -0.809889  1.077737   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284 -0.511180  1.077737   \n",
       "\n",
       "        RAD       TAX   PTRATIO  ...    NOX_RM    RM_AGE        RM      RM_2  \\\n",
       "0 -0.982843 -0.666608 -1.459000  ... -0.059659 -0.049646  0.413672  0.171124   \n",
       "1 -0.867883 -0.987329 -0.303094  ... -0.143814  0.071331  0.194274  0.037743   \n",
       "2 -0.867883 -0.987329 -0.303094  ... -0.949544 -0.340960  1.282714  1.645354   \n",
       "3 -0.752922 -1.106115  0.113032  ... -0.848901 -0.823092  1.016303  1.032871   \n",
       "4 -0.752922 -1.106115  0.113032  ... -1.026210 -0.628023  1.228577  1.509401   \n",
       "\n",
       "       RM_3      RM_4     LSTAT   LSTAT_2   LSTAT_3   LSTAT_4  \n",
       "0  0.070789  0.029284 -1.075562  1.156834 -1.244247  1.338266  \n",
       "1  0.007332  0.001425 -0.492439  0.242497 -0.119415  0.058805  \n",
       "2  2.110519  2.707191 -1.208727  1.461022 -1.765977  2.134585  \n",
       "3  1.049709  1.066822 -1.361517  1.853728 -2.523882  3.436308  \n",
       "4  1.854414  2.278290 -1.026501  1.053705 -1.081630  1.110295  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061549447223175"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "result = np.mean(cross_val_score(LR, df_inter, y, scoring=\"r2\", cv=crossvalidation))\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've learned that, when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter alpha of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC\n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(df_inter, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(df_inter, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color, linewidth=2, label= name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=2,\n",
    "                label='alpha for %s ' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'green')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'blue')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for regularization parameter according to AIC and BIC and compare the R squared parameters and MSE using train-test-split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.7346543792695568\n",
      "Testing r^2: 0.7335453453995047\n",
      "Training MSE: 21.232289590741185\n",
      "Testing MSE: 25.88772882029599\n"
     ]
    }
   ],
   "source": [
    "# Code for baseline model\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y)\n",
    "\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "print('Training r^2:', linreg_all.score(X_train, y_train))\n",
    "print('Testing r^2:', linreg_all.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg_all.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, linreg_all.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8492226652223259\n",
      "Testing r^2: 0.821555978083574\n",
      "Training MSE: 12.78946847465053\n",
      "Testing MSE: 14.841641470138384\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from AIC\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inter, y)\n",
    "\n",
    "lasso1 = Lasso(model_aic.alpha_)\n",
    "lasso1.fit(X_train, y_train)\n",
    "print('Training r^2:', lasso1.score(X_train, y_train))\n",
    "print('Testing r^2:', lasso1.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso1.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, lasso1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8470164165348338\n",
      "Testing r^2: 0.8250342349528272\n",
      "Training MSE: 12.976610315813353\n",
      "Testing MSE: 14.55234603261075\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from BIC\n",
    "lasso2 = Lasso(model_bic.alpha_)\n",
    "lasso2.fit(X_train, y_train)\n",
    "print('Training r^2:', lasso2.score(X_train, y_train))\n",
    "print('Testing r^2:', lasso2.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso2.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, lasso2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso Path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-Learn there is a function lasso_path which visualizes the shrinkage of the coefficients while alpha changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston Housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
